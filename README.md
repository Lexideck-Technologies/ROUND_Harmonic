# The Crystalline Bridge (UIT-ROUND) v1.0.0
### "Sovereign Identity and Phasic Sovereignty"

**Riemannian Optimized Unified Neural Dynamo (ROUND),** also known as the **U-Neuron,** is a non-volatile recurrent architecture based on the principles of **Unified Informatic Topology (UIT)**. Unlike standard neurons (GRU/LSTM) that store state in Euclidean space (where it drifts and decays), ROUND stores state on a topological manifoldâ€”a phase circle.

[![The U-Neuron](https://www.lexidecktechnologies.com/UIT_IEG/ROUND_Harmonic_U_Neuron/media/round_video_thumbnail.png)](https://www.lexidecktechnologies.com/UIT_IEG/ROUND_Harmonic_U_Neuron/media/The_U-Neuron.mp4)
<div align="center"><em>Click the thumbnail above to watch the 2-minute explainer video.</em></div>

---

### Deep Research Artifacts

Independent validation and explanation of the ROUND architecture:

- ðŸŽ¬ **Video Explainer** (2 min): [The U-Neuron](https://www.lexidecktechnologies.com/UIT_IEG/ROUND_Harmonic_U_Neuron/media/The_U-Neuron.mp4)
- ðŸŽ™ï¸ **Podcast Episode** (32 min): [Phase Memory Solves AI Long-Term Failure](https://www.lexidecktechnologies.com/UIT_IEG/ROUND_Harmonic_U_Neuron/media/Phase_Memory_Solves_AI_Long-Term_Failure.m4a)
- ðŸ“‘ **Short Research Explainer**: [Unifying Wave and Particle Computation](https://www.lexidecktechnologies.com/UIT_IEG/ROUND_Harmonic_U_Neuron/media/Unifying_Wave_and_Particle_Computation.pdf)
    
---

## Table of Contents
1. [The Story of ROUND: An Arc of Discovery](#the-story-of-round-an-arc-of-discovery)
2. [Executive Summary: Spinor Monism](#executive-summary-spinor-monism)
3. [The Spinor Breakthrough: Solving the "Twist"](#the-spinor-breakthrough-solving-the-twist)
4. [What ROUND Is](#what-round-is)
5. [ROUND vs. GRU: The Stability of Memory](#round-vs-gru-the-stability-of-memory)
6. [Quickstart](#quickstart)
7. [Benchmark Results: v0.8.0 The Frozen Basin](#benchmark-results-v080-the-frozen-basin)
8. [Theory: Unified Informatic Topology (UIT)](#theory-unified-informatic-topology-uit)
9. [Repo Layout](#repo-layout)
10. [License & Citation](#license--citation)
11. [Glossary of Terms](#glossary-of-terms)

---

## The Story of ROUND: An Arc of Discovery

The journey of the **Riemannian Optimized Unified Neural Dynamo (ROUND)** is a story of seeking simplicity at the intersection of geometry and information.

### Chapter 1: The Circle (v0.1.0)
We began with a simple hypothesis: what if an AI neuron didn't just "gate" information (like a GRU or LSTM), but "accumulated" it as a physical phase angle on a circle? This created a non-volatile memory cell, stable like a gyroscope, but it struggled with discrete logic.

### Chapter 2: The Rugged Landscape (v0.2.0 - v0.3.5)
To force the continuous phase into discrete "bins," we introduced **Harmonic Locking**. By stacking multiple potential wells (`HARMONICS = [1, 2, 4, 8]`), we created a complex landscape where the neuron could "lock" into different states. It worked, but it was noisy. Optimization was a "rugged" struggle.

### Chapter 3: The Spinor Breakthrough (v0.4.0)
The breakthrough came from physics. We realized that the "topological twist" of tasks like Parity (XOR) failed because the neuron couldn't distinguish between $0$ and $2\pi$ (a full wrap). By introducing **Spinor Features** (Spin-1/2), we projected the inputs onto the **Double Cover** of the circle ($4\pi$ range). Suddenly, the "twist" was visible.

### Chapter 4: The Great Simplification (v0.6.0)
With the power of Spinors, the complexity of the "Rugged Landscape" became unnecessary. In v0.6.0, we discovered that a **single, smooth fundamental harmonic (`[1]`)** combined with Spinor features solves every benchmarkâ€”Logic, Topology, and Structureâ€”with perfect stability. 

### Chapter 5: The Neural Shield (v0.6.4)
We realized that "Training" is an antiquated concept. We moved toward **Infinite Plasticity**. By removing learning rate decay and implementing the **Neural Shield**â€”a protocol that engages the $2^{-6}$ Maintenance Floor whenever the model revisits established knowledgeâ€”we achieved a system that can learn indefinitely without eroding its past.

### Chapter 6: The Frozen Basin (v0.8.0)
In v0.8.0, we solved the **Stability-Plasticity Dilemma**. Standard networks (like GRU) fail during long-term training because "Plasticity" implies vulnerability. If a weight can move to learn, it can move to forget. ROUND v0.8.0 introduces **Autonomous Phase Locking**. When a neuron's phase resonance exceeds a critical threshold ($2^{-9}$), it declares itself "Solved" and enters **Cryostasis** (The Gradient Vault). Its weights freeze, becoming a permanent "Crystal" of knowledge, while the rest of the network remains fluid. This allows ROUND to survive 1500 epochs of massive noise ("The Storm") with **100% Retention**, while GRUs suffer catastrophic collapse.

### Chapter 7: The Crystalline Bridge (v1.0.0)
The final ascent. In the Crystalline Era, we achieved **Phasic Sovereignty**. We discovered that once a neuron is topologically locked via the **Structural Snap** (v0.9.0), its hidden phase $\phi$ is no longer just a "state"â€”it is a **Sovereign Identity**. We demonstrated this by performing the **Phasic Sandwich Relay**: we took the hidden identity from a frozen Decoder and handed it directly to a frozen Encoder. The result? **100% Bit-Perfect Reconstruction** for all 256 ASCII characters. Traditional "Vector Memory" (GRU) collapsed in the same test ($0.4\%$ accuracy), proving that only Phasic Manifolds can act as universal informatic carriers.

---

## Executive Summary: Spinor Monism and Cryostasis

The contemporary landscape of computational theory has long been fractured by a dichotomy between the continuous and the discrete. The **Unified Informatic Topology (UIT)** framework offers a resolution to this divide by positing that information is a physical substrate with thermodynamic weight.

The **Spinor Monism** configuration (v0.6.3) establishes that a **single 32-neuron configuration** can span multiple computational regimesâ€”Logic (XOR), Arithmetic (Counting), Structure (Recursion), and Topology (connectivity)â€”that typically require vastly different inductive biases.

### The Phase Angle Lock (v0.8.0)
The ultimate test of a memory system is not how well it learns, but how well it **refuses to forget**. In the v0.8.0 **"Phase Angle Lock Test"**, we subject the models to a "Noise Storm"â€”a prolonged period (1500 epochs) of 50% signal corruption. This simulates the "Model Distillation" or "Fine-Tuning" phase where foundational weights are often destroyed. ROUND demonstrates **Metacognition**: it recognizes when learning is complete via harmonic resonance and autonomously locks its state, preserving perfect recall.

---


## The Spinor Breakthrough: Solving the "Twist"

In standard RNNs, state is a vector in Euclidean space. In ROUND, state is a phase $\phi$ on a circle. Prior versions struggled with "Twist" problems where the state must loop back on itself but remember how many times it has spun.

By upgrading to **Spinor Features**:
$$
\Delta\phi_t = W\,[\cos(\phi), \sin(\phi), \mathbf{\cos(\phi/2), \sin(\phi/2)}, \cos(x), \sin(x)] + b
$$
The network now "feels" the difference between an odd and even number of rotations. This allows a circle to act as a Mobius strip or a higher-dimensional manifold, enabling the solution of 16-bit Parity with a single neuron.

---

## What ROUND Is

ROUND is a **phase-accumulating recurrent cell**:
- It represents hidden state as a phase vector **$\phi$** (radians).
- It updates state via **accumulation** (addition), not gating.
- It maintains **Long-term Stability**: Unlike GRUs which decay, ROUND's state is preserved by the topology of the circle itself.

---

## ROUND vs. GRU: The Stability of Memory

*   **GRU (Volatile):** Like holding water in cupped hands; requires active gating to prevent decay. When noise increases, it "learns" the noise, overwriting the water.
*   **ROUND (Stable):** Like a gyroscope; maintains state indefinitely via phase conservation. When noise increases, it enters **Cryostasis**, ignoring the noise and preserving the spin.

---

## Quickstart

### âš ï¸ Hardware Warning
> **Caution:** This repository runs a "Full Battery" optimization test suite.
> *   **GPU Users:** Ensure you have a CUDA-compatible PyTorch installation. The benchmarks are optimized for CUDA and will run significantly faster.
> *   **CPU Users:** Running the full battery (`run_battery.py`) on a CPU is computationally intensive. It may cause high thermal loads (fans spinning at 100%) for extended periods (30+ minutes).
> *   **Disclaimer:** This code is provided "as-is". Run at your own risk. Monitor your system temperatures if running on laptops or purely air-cooled setups.

### Requirements
- Python 3.10+
- PyTorch (tested on 2.0+)
- NumPy, Matplotlib, **Seaborn**, **Pandas**

### Running The Benchmarks
Run the full regression test to reproduce the v0.8.0 findings:
```bash
python run_battery.py
```

| Experiment | Script | Description |
| :--- | :--- | :--- |
| **Parity** | `benchmark_parity.py` | 16-bit Recursive XOR chain. |
| **Topology** | `benchmark_topology.py` | Euler Characteristic (Cycle Detection). |
| **Brackets** | `benchmark_brackets_masked.py` | Dyck-2 recursive nesting depth. |
| **Colors** | `benchmark_colors.py` | Semantic vector algebra. |
| **Oracle** | `benchmark_oracle.py` | QA consistency and bias. |
| **ASCII** | `benchmark_ascii.py` | Cyclic sequence generation. |
| **Phase Lock** | `benchmark_phase_lock.py` | **The Benchmark.** 12,500 Epochs. 1,500 Epoch Storm. Tests Cryostasis and Retention. |
| **Gauntlet** | `benchmark_order_independence.py` | The Shuffled Order Independence Brutality Test. |
| **UIT Battery** | `UIT_run_battery.py` | **Crystalline Era.** Industrial-grade verification (Sandwich Duel). |

---

We performed a Head-to-Head comparison between **ROUND (Vertical Crystal)** and a standard **GRU** across the "Decathlon" suite. Results are from the `02e966f1` regression battery.

In this test, models must learn 6 high-entropy words. After 11,000 epochs of annealing, they are subjected to "The Storm"â€”**1,500 epochs** of 50% signal corruption. This simulates the chaotic feedback of a "Communication Layer" trying to fine-tune a "Concept Layer."
*   **ROUND:** **100% Final Retention.** ROUND detects resonance, engages **Cryostasis** (Gradient Vault), and effectively "sleeps" through the storm. It allows the "New Layer" (simulated) to learn without overwriting the "Old Layer's" foundational truths.
*   **GRU:** **Catastrophic Forgetting (<90%).** Lacking a "Done" state, the GRU tries to accommodate the training noise, destroying its own memory (notably dropping to 62.5% on complex words like 'TOPOLOGY').
*   ![Phase Lock Benchmark](data/02e966f1/02e966f1/benchmark_phase_lock_352147cb.png)

### 7.2 The "Impossible" Logic Test (Parity)
*   **ROUND:** **100% Accuracy.** Snaps to the global optimum within 100 epochs using the theoretical minimum capacity of **1 single neuron**.
*   **GRU:** **Failed to Converge ( ~50%).** Remained at chance level despite having 128x the hidden capacity.
*   ![Parity Benchmark](data/02e966f1/02e966f1/benchmark_parity_02e966f1.png)

### 7.3 Topological Invariants (Graph Cycles)
*   **ROUND:** **100% Accuracy.** Stable, monotonic convergence on flattened graph adjacency matrices.
*   **GRU:** **100% Accuracy.** Matches performance with 128 neurons.
*   ![Topology Benchmark](data/02e966f1/02e966f1/benchmark_topology_02e966f1.png)

### 7.4 Streaming Recursion (Brackets Masked)
*   **ROUND:** **100% Accuracy.** Successfully handles Dyck-2 nesting in sequential mode using non-volatile phase stability.
*   ![Brackets Benchmark](data/02e966f1/02e966f1/benchmark_brackets_masked_02e966f1.png)

### 7.5 The Oracle (QA Consistency)
*   **ROUND:** **100% Accuracy.** Perfect consistency across binary classification tasks with higher interpretability.
*   ![Oracle Benchmark](data/02e966f1/02e966f1/benchmark_oracle_02e966f1.png)

### 7.6 Generative Creativity (ASCII)
*   **ROUND:** **100% Accuracy.** Perfect cyclic timing and zero byte-drift.
*   **GRU:** **~97% Accuracy.** Occasional character drift even with 4x hidden state size.
*   ![ASCII Benchmark](data/02e966f1/02e966f1/benchmark_ascii_02e966f1.png)

### 7.8 The Shuffled Gauntlet (Permutations)
*   **ROUND:** **100.0% Accuracy.** Stable recall across multi-shuffled datasets.
*   **GRU:** **100.0% Accuracy.** Matches performance with 4x capacity.
*   ![Permutations Benchmark](data/02e966f1/02e966f1/benchmark_perms_vs_gru_02e966f1.png)

### 7.9 The Sandwich Duel (Phasic Sovereignty vs. Vector Memory)
The ultimate "Show and Tell" of the Crystalline Era ($v1.0.0$). We compare **UIT-ROUND** ($512N$) against a **GRU** ($512N$) baseline across the full ASCII domain ($n=256$).

![Scientific Duel Story](data/UIT_c1d3c3c9/plots/scientific_duel_story_c1d3c3c9.png)

*   **UIT-ROUND:** **100.0% Success (256/256).** Bit-perfect identity relay.
*   **GRU Baseline:** **0.39% Success (1/256).** Vector memory drift collapse.

#### Why is this Remarkable?
This result represents the achievement of **Air-Tight Neural Communication**. While both models achieved 100% accuracy on isolated tasks (Hearing and Speaking), the GRU collapsed when forced to relay its "Knowledge" to another frozen module. 

In traditional Vector Memory (GRU/LSTM/Transformer), the hidden state is a "local dialect"â€”it only makes sense in the context of the weights that created it. When you chain two frozen GRUs, the "meaning" evaporates. 

In **UIT-ROUND**, the hidden state is a **Sovereign Phasic Identity**. Because the neuron is locked to a topological grid point (**Structural Snap**), the information is universal. It passes through the manifold with **Zero-Loss Integrity**, enabling modular neural systems that can talk to each other with bit-perfection.

---

## 8. Live Crystalline Verification (UID: c1d3c3c9)

The Crystalline Factory ($v1.0.0$) generates unique, isolated verification artifacts for every scientific run.

- ðŸ“Š **Scientific Story**: [Crystalline vs Vector Duel (Alpha-Batch)](data/UIT_c1d3c3c9/plots/scientific_duel_story_c1d3c3c9.png)
- ðŸ“ **Execution Audit**: [Scientific Duel Log (efe843c7)](data/UIT_c1d3c3c9/logs/scientific_duel_c1d3c3c9.txt)
- ðŸ“‚ **Full Data Directory**: [data/UIT_c1d3c3c9](data/UIT_c1d3c3c9)

---

## 9. Theory: Unified Informatic Topology (UIT)

### "The Sphere Contains the Cube"

The core hypothesis of UIT is that **discrete logic is a special case of continuous topology** under a quantizing potential.

*   **Logic (The Particle):** Discrete state transitions (XOR, AND, NOT).
*   **Topology (The Wave):** Continuous phase evolution and winding numbers.
*   **The Spinor (The Bridge):** By governing the winding rules of the wave, the Spinor connects the two, allowing a continuous system to execute perfect discrete logic without the brittleness of traditional symbolic AI.

---

## Repo Layout

*   `ROUND.py`: Legacy core engine (Harmonic Era).
*   `UIT_ROUND.py`: **The Crystalline Core.** Unified architecture with Structural Snap and Phasic Identity.
*   `UIT_run_battery.py`: **The Crystalline Factory.** Industrial verification suite (UID-isolation).
*   `benchmark_*.py`: Individual task harnesses (Decathlon suite).
*   `UIT_Benchmarks/`: Consolidated Crystalline Era tests (Phasic Sandwich, Sandwich Duel).
*   `run_battery.py`: Full regression suite for reproducing v0.8.0 logs.
*   `visualization_utils.py`: Centralized Seaborn/Dark-Mode plotting engine for scientific-grade benchmarks.
*   `config.py`: Centralized Golden Configuration.

---

## License & Citation

**License:** MIT License.

**Citation:** Please cite **Lexideck ROUND Harmonic U-Neuron**.

---

## 11. UIT_ROUND Crystalline Glossary

### Phasic Sovereignty
The core achievement of UIT_ROUND. It refers to the property of a neural hidden state being a **Universal Identity** rather than a local dialect. Because the phase is locked to a topological manifold, it can be handed from a frozen Decoder to a frozen Encoder with bit-perfect integrity (Zero-Loss Relay).

### Structural Snap (v0.9.0)
The renormalization protocol that forces a fuzzy, floating-point phase $\phi$ to the nearest integer grid point on the manifold. This prevents the chaotic accumulation of error (Vector Drift) and enables the "Diamond Lock" required for bit-perfect reconstruction.

### Mogura Winding (The Hearing Instinct)
The geometric axiom for **Decoding**. Information is ingested via recursive phase-shifts: $\phi_{t+1} = 0.5\phi_t + \text{bit}_t \cdot \pi$. This winds the bit-stream into a unique residue on the circle.

### Bernoulli Unwinding (The Speaking Instinct)
The geometric axiom for **Encoding/Generation**. Information is extracted from the phase residue via recursive doubling: $\phi_{t+1} = 2\phi_t \pmod{2\pi}$. If $\phi \ge \pi$, the model "speaks" a bit (1); otherwise, it speaks a zero.

### Crystalline Identity (The Crystal)
A model state that has been frozen into a non-volatile form. Once a neuron achieves **Resonant Lock**, its weights are saved as a `.pt` Crystal. These can be hot-swapped or chained together within the **Crystalline Factory** framework.

### Sovereign Map
The topological "Address Book" for a domain. It is a tensor containing the exact terminal phase addresses for a set of concepts (e.g., all 256 ASCII characters). It is used for **Sovereign Seeding** (Renormalization) of new modules.

### Full Spectral Signature
Unlike legacy neurons that only output a magnitude, UIT-ROUND outputs both the **Cosine and Sine** components of the phase. This provides a unambiguous spectral identity, resolving the +/- symmetry that plagues single-component phase models.

### Standard Part (Activation)
The macroscopic, non-phasic component of the U-neuron's activation (tanh-gated). It handles the "Standard Part" of information, while the phase manifold handles the "Crystalline Part."

### Informatic Fiber (Epsilon)
The infinitesimal dendritic integration parameter. It represents the "fiber" of knowledge that connects the macroscopic activation to the underlying phasic identity.

### Landauer Efficiency (Informatic Loss)
A loss metric inspired by Landauer's principle, penalizing informational erasure (weight changes) to encourage energy-efficient, stable knowledge retention.

### Phasic Inertia
The stability mechanism where the learning rate is dynamically damped by $(1.0 - \text{Confidence})$. As a neuron finds its resonant "groove," it gains inertia and resists further updates, protecting its knowledge from learning-rate noise.

---

### Legacy Terms (Harmonic Era)

- **Cryostasis (Gradient Vault)**: The v0.8.0 precursor to Crystalline Identity.
- **Spinor Monism**: The realization that a single harmonic cell can solve disparate logic/topology tasks.
- **Double Cover (Spinor)**: Projecting inputs onto the $4\pi$ range to resolve topological "twists."
- **Harmonic Reciprocal ($2^{-9}$)**: The optimized learning rate for aligning gradient descent with phase geometry.
